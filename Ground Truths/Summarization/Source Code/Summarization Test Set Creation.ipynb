{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83aa55c2",
   "metadata": {},
   "source": [
    "*Licensed under the MIT License. See LICENSE-CODE in the repository root for details.*\n",
    "\n",
    "*Copyright (c) 2025 Eleni Kamateri*\n",
    "\n",
    "### Classification Test Set Creation (Ground Truth)\n",
    "\n",
    "This script facilitates the creation of summarization test sets (i.e., ground truth), using a CSV file as input. The CSV file contains essential data for patents within a specific core vertical (e.g., EP).\n",
    "\n",
    "#### Overview\n",
    "\n",
    "The script is divided into four key parts:\n",
    "\n",
    "- Part I: Selects patents meeting specific criteria for inclusion in the test set.\n",
    "- Part II: Retrieves textual data from the original WPI collection.\n",
    "- Part III: Extracts key textual sections, including the brief description, the summary segment of the description and the first claim.\n",
    "- (Optionally) Part IV: Filters patents based on additional selection criteria.\n",
    "\n",
    "This methodology ensures a structured, high-quality dataset for training and evaluating summarization models on patent data.\n",
    "\n",
    "### Selection Criteria for Test Set (Part I)\n",
    "\n",
    "Patents included in the test sets must meet the following criteria:\n",
    "\n",
    "1. Complete textual fields: The patent must include an abstract, description, and claims.\n",
    "2. B kind code selection: The patent must have a B kind code (e.g., B1, B2, B3, B6, B8, B9).\n",
    "3. Date restriction: The patent must have been submitted in the last quarter of 2015 (i.e., after October 1, 2015). \n",
    "\n",
    "### Textual Data Retrieval (Part II)\n",
    "To create a summarization dataset that is ready for use, we need to retrieve key textual sections from the original WPI collection:\n",
    "\n",
    "1. Abstract – Serves as the reference summary.\n",
    "2. Description – Typically used as input for generating summaries.\n",
    "3. Claims – Typically included in the input text, as they define the scope of the invention.\n",
    "4. Title – Provides additional context and may help improve summarization quality.\n",
    "\n",
    "By ensuring these sections are included, the dataset will be structured and comprehensive, supporting high-quality summarization tasks.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip for Part III:</b> To ensure proper extraction of patent text in Part III, the get function should separate the text it retrieves using a line separator ('\\n ').\n",
    "</div>\n",
    "\n",
    "### Brief Description, Summary, and First Claim Extraction (Part III)\n",
    "This step extracts key sections from each patent:\n",
    "\n",
    "- Brief description\n",
    "- Summary section\n",
    "- First claim\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Tip:</b> To ensure proper extraction of patent text:\n",
    "    \n",
    "- description section must include author-annotated headings.\n",
    "    \n",
    "- claims section must follow a standard numbering format (e.g., starting from \"1.\"). If these structural markers are missing, the algorithm may not detect the first claim. \n",
    "</div>\n",
    "\n",
    "### Additional Criteria for Test Set (Part IV) (Optional)\n",
    "Further refinement of the summarization test set can be applied by:\n",
    "\n",
    "1. Filtering patents without a distinct summary segment\n",
    "2. Removing patents where the abstract has low similarity with the description and summary segment\n",
    "\n",
    "These additional filters help maintain high-quality and coherent summarization data.\n",
    "\n",
    "### Important Note\n",
    "\n",
    "Virtual patents were created by merging different kind codes of the same patent, retaining the latest information for each field.\n",
    "\n",
    "### Configurable Parameters\n",
    "\n",
    "Researchers can modify the following parameters to customize the test set generation:\n",
    "\n",
    "**csv_file_path** – Path to the CSV file containing essential data for analyzing the specific vertical.\n",
    "\n",
    "**vertical_origin_path** – Path to the core vertical of the WPI dataset, containing the extracted files to be parsed for CSV creation. \n",
    "\n",
    "        Example: \"/YOUR_PATH/WPI-Dataset/EP/\". \n",
    "        \n",
    "**destination_path** – Path to the folder where the generated files will be stored. \n",
    "\n",
    "**sep** – Defines the separator used in the CSV file:\n",
    "\n",
    "        0: Semicolon (;)\n",
    "        \n",
    "        1: Comma (,)\n",
    "              \n",
    "**kind_code_selection** – Selects the type of documents for the test set:\n",
    "        \n",
    "        0: B documents (default).\n",
    "        \n",
    "        1: A documents (for cases like the WO core vertical, which only has A documents).\n",
    "        \n",
    "**date_selection** – Allows modification of the date criteria for selected documents.\n",
    "\n",
    "        20151000 (default).\n",
    "                \n",
    "The code below creates summarization test sets for the #EP core vertical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652a3e7d",
   "metadata": {},
   "source": [
    "### Set the required parameters for the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "863e56e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path='/YOUR_PATH/EP_csv_file_for_wpi_analysis.csv'\n",
    "vertical_origin_path=\"/YOUR_PATH/WPI-Dataset/EP/\"\n",
    "destination_path=\"/YOUR_PATH/WPI-Dataset/\"\n",
    "filename1=\"1\"\n",
    "filename2=\"2\"\n",
    "filename3=\"3\"\n",
    "sep=0\n",
    "kind_code_selection=0\n",
    "date_selection=20151000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hguRr7BD5F3q",
   "metadata": {
    "id": "hguRr7BD5F3q"
   },
   "source": [
    "### Import all required libraries for the script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e326b4a-e85f-4274-a2fb-44cba02ace99",
   "metadata": {
    "id": "Ab8Fy261ZeM9"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jlSog7u95S6P",
   "metadata": {
    "id": "jlSog7u95S6P"
   },
   "source": [
    "### Import the CSV file and load its data into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "266af9c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 2615,
     "status": "ok",
     "timestamp": 1738875912146,
     "user": {
      "displayName": "Eleni Kamateri",
      "userId": "17468520200409985303"
     },
     "user_tz": -120
    },
    "id": "266af9c0",
    "outputId": "1a0de3fe-c730-4c5b-8b6e-494422642c08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(552439, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>xml_file_name</th>\n",
       "      <th>ucid</th>\n",
       "      <th>date</th>\n",
       "      <th>main_classification</th>\n",
       "      <th>further_classification</th>\n",
       "      <th>classification_ipcr</th>\n",
       "      <th>classification_cpc</th>\n",
       "      <th>abstract_lang_en_exist</th>\n",
       "      <th>description_lang_en_exist</th>\n",
       "      <th>claims_lang_en_exist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>EP-2677851-A1.xml</td>\n",
       "      <td>EP-2677851-A1</td>\n",
       "      <td>20140101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A01B  79/02        20060101AFI20120911BHEP    ...</td>\n",
       "      <td>A01B  79/005       20130101 LI20150420BHEP    ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0      xml_file_name           ucid      date main_classification  \\\n",
       "0           0  EP-2677851-A1.xml  EP-2677851-A1  20140101                 NaN   \n",
       "\n",
       "  further_classification                                classification_ipcr  \\\n",
       "0                    NaN  A01B  79/02        20060101AFI20120911BHEP    ...   \n",
       "\n",
       "                                  classification_cpc  abstract_lang_en_exist  \\\n",
       "0  A01B  79/005       20130101 LI20150420BHEP    ...                     1.0   \n",
       "\n",
       "   description_lang_en_exist  claims_lang_en_exist  \n",
       "0                        1.0                   1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if sep==0:\n",
    "    DF = pd.read_csv(csv_file_path, header=0, delimiter=\";\") #, nrows=1000)\n",
    "elif sep==1:\n",
    "    DF = pd.read_csv(csv_file_path, header=0) #, nrows=1000)\n",
    "else:\n",
    "    print(\"Please provide a valid value for sep\")\n",
    "\n",
    "print(DF.shape)\n",
    "DF.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b88b18",
   "metadata": {},
   "source": [
    "### Identify the patent number and kind code, and append these fields to the initial DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ab9924f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF['patent_number']=DF['xml_file_name'].str.split(\".\").str[0]\n",
    "DF['patent_number']=DF['patent_number'].str.split(\"-\").str[1:2]\n",
    "DF['patent_number']=DF['patent_number'].str.join('')\n",
    "\n",
    "DF['kind_code']=DF['xml_file_name'].str.split(\".\").str[0]\n",
    "DF['kind_code']=DF['kind_code'].str.split(\"-\").str[2:3]\n",
    "DF['kind_code']=DF['kind_code'].str.join('')\n",
    "\n",
    "DF['kind_code_letter']=DF['kind_code'].str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ae360a",
   "metadata": {},
   "source": [
    "# Selection Criteria for Test Set (Part I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cQSfh3L91Sv",
   "metadata": {
    "id": "0cQSfh3L91Sv"
   },
   "source": [
    "### Filter patents based on the first and second criteria\n",
    "Retain only the patents that:\n",
    "1. Have all textual fields completed (i.e., abstract, description, and claims).\n",
    "2. Belong to a B kind code (i.e., B1, B2, B3, B6, B8, B9)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "z0Mhsjv99zZg",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4309,
     "status": "ok",
     "timestamp": 1738876083958,
     "user": {
      "displayName": "Eleni Kamateri",
      "userId": "17468520200409985303"
     },
     "user_tz": -120
    },
    "id": "z0Mhsjv99zZg",
    "outputId": "80ebee10-1237-4e96-96cf-01155b1cba9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patent documents: (19313, 14) Number of single patents: (9261, 4)\n"
     ]
    }
   ],
   "source": [
    "# Find patent_numbers being \"A\" or \"B\" kind code\n",
    "if kind_code_selection==0:\n",
    "    DF_1=DF[DF['kind_code_letter']=='B']\n",
    "elif kind_code_selection==1:\n",
    "    DF_1=DF[DF['kind_code_letter']=='A']\n",
    "else:\n",
    "    print(\"Please provide a valid value for kind_code_selection\")\n",
    "    \n",
    "DF_1 =DF_1.loc[:, ['patent_number']]\n",
    "\n",
    "# Find patent_numbers having all textual fields completed in any of the kind code documents\n",
    "DF_2=DF.copy()\n",
    "DF_2['adc_exist']= None\n",
    "DF_2['abstract_lang_en_exist'] = DF_2['abstract_lang_en_exist'].replace({0:np.nan})\n",
    "DF_2['description_lang_en_exist'] = DF_2['description_lang_en_exist'].replace({0:np.nan})\n",
    "DF_2['claims_lang_en_exist'] = DF_2['claims_lang_en_exist'].replace({0:np.nan})\n",
    "DF_2=DF_2.groupby('patent_number').agg({'abstract_lang_en_exist':'last', 'description_lang_en_exist': 'last', \\\n",
    "                                     'claims_lang_en_exist':'last', 'patent_number':'last'})\n",
    "DF_2 = DF_2.reset_index(drop=True)\n",
    "DF_2['adc_exist']=DF_2['abstract_lang_en_exist']+DF_2['description_lang_en_exist']+DF_2['claims_lang_en_exist']\n",
    "DF_2=DF_2[DF_2['adc_exist']==3]\n",
    "DF_2 =DF_2.loc[:, ['patent_number']]\n",
    "\n",
    "# Find patent_numbers satisfying both above criteria\n",
    "# Specifically, merge the two dataframes and since a patent_number may appear more than one time, delete duplicates.\n",
    "DF_12 = pd.merge(DF_1, DF_2, on=['patent_number'])\n",
    "DF_12 = DF_12.drop_duplicates(subset = [\"patent_number\"])\n",
    "DF_12=DF_12.sort_values(by = 'patent_number', ascending=True)\n",
    "\n",
    "# Create a list with the detected patent_numbers and remove from the initial dataframe the patent_numbers not listed in this list\n",
    "doc_number_list=DF_12['patent_number'].tolist()\n",
    "DF_subpart = DF[DF['patent_number'].isin(doc_number_list)]\n",
    "\n",
    "# In case of more than one kind codes for a patent, group them and keep the latest non empty field\n",
    "DF_subpart_merged=DF_subpart.groupby('patent_number').agg({'xml_file_name':'last', 'ucid':'last', 'date':'last', 'patent_number':'last'})\n",
    "DF_subpart_merged = DF_subpart_merged.reset_index(drop=True)\n",
    "print(\"Number of patent documents:\",DF_subpart.shape, \"Number of single patents:\", DF_subpart_merged.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "DEED0Ge-FNxo",
   "metadata": {
    "id": "DEED0Ge-FNxo"
   },
   "source": [
    "### Filter patents based on the third criterion\n",
    "Retain only the patent documents that:\n",
    "- Were submitted in the last quarter of 2015 (i.e., after October 1, 2015)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "D0P9lZC0v7UC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1738876083959,
     "user": {
      "displayName": "Eleni Kamateri",
      "userId": "17468520200409985303"
     },
     "user_tz": -120
    },
    "id": "D0P9lZC0v7UC",
    "outputId": "9cf5ce84-24e8-49f9-e372-705a847dce80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patent documents: (2855, 14) Number of single patents: (2847, 4)\n"
     ]
    }
   ],
   "source": [
    "DF_subpart_2=DF_subpart[DF_subpart['date']>date_selection]\n",
    "DF_subpart_2_merged=DF_subpart_merged[DF_subpart_merged['date']>date_selection]\n",
    "print(\"Number of patent documents:\",DF_subpart_2.shape, \"Number of single patents:\", DF_subpart_2_merged.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b604f96",
   "metadata": {},
   "source": [
    "# Textual Data Retrieval (Part II)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56b7d83",
   "metadata": {},
   "source": [
    "Once we have the list of patent numbers that satisfy the selection criteria in Part I, the next step is to retrieve the corresponding full-text data (abstract, description, claims, title) from the original WPI collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cda6c93a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "200000\n",
      "300000\n",
      "400000\n",
      "500000\n"
     ]
    }
   ],
   "source": [
    "# Count the time\n",
    "start_time = time.time()\n",
    "df_sum_test = pd.DataFrame()\n",
    "counter_sum=0\n",
    "\n",
    "DF_patent_number_list=DF_subpart_2_merged['patent_number'].tolist()\n",
    "\n",
    "for folder_level_1 in os.listdir(vertical_origin_path): #CC\n",
    "    for folder_level_2 in os.listdir(vertical_origin_path+\"/\"+folder_level_1): #nnnnnn\n",
    "        for folder_level_3 in os.listdir(vertical_origin_path+\"/\"+folder_level_1+\"/\"+folder_level_2): #nn\n",
    "            for folder_level_4 in os.listdir(vertical_origin_path+\"/\"+folder_level_1+\"/\"+folder_level_2+\"/\"+folder_level_3): #nn\n",
    "                for folder_level_5 in os.listdir(vertical_origin_path+\"/\"+folder_level_1+\"/\"+folder_level_2+\"/\"+folder_level_3+\"/\"+folder_level_4): #nn                                        \n",
    "                    for folder_level_6 in os.listdir(vertical_origin_path+\"/\"+folder_level_1+\"/\"+folder_level_2+\"/\"+folder_level_3+\"/\"+folder_level_4+\"/\"+folder_level_5): #nn                                        \n",
    "                        for files in os.listdir(vertical_origin_path+\"/\"+folder_level_1+\"/\"+folder_level_2+\"/\"+folder_level_3+\"/\"+folder_level_4+\"/\"+folder_level_5+\"/\"+folder_level_6): #nn                                        \n",
    "\n",
    "                            counter_sum=counter_sum+1                    \n",
    "                            if counter_sum%100000==0:\n",
    "                                print(counter_sum)\n",
    "                            files_proc=files.split(\".\")[0]\n",
    "                            \n",
    "                            try:\n",
    "                                doc_number_proc=files_proc.split(\"-\")[1]\n",
    "                            except Exception:\n",
    "                                doc_number_proc=''\n",
    "                                print(\"Exception with doc-number\", files)\n",
    "                                \n",
    "                            if doc_number_proc in DF_patent_number_list:                                                        \n",
    "                                \n",
    "                                title_en_text  = ''     \n",
    "                                abstract_en_text   = ''                                        \n",
    "                                description_en_text = ''                                                   \n",
    "                                claims_en_text = ''\n",
    "\n",
    "                                content = open(vertical_origin_path+\"/\"+folder_level_1+\"/\"+folder_level_2+\"/\"+folder_level_3+\"/\"+folder_level_4+\"/\"+folder_level_5+\"/\"+folder_level_6+\"/\"+files,'r',encoding='utf-8').read()\n",
    "                                soup = BeautifulSoup(content, 'xml')\n",
    "                                document_info = soup.find_all(\"patent-document\")  \n",
    "\n",
    "                                try:\n",
    "                                    ucid=document_info[0]['ucid']\n",
    "                                except Exception:\n",
    "                                    ucid=''\n",
    "                                    print(\"Exception 1, ucid does not exist\", files)\n",
    "                                                       \n",
    "                                try:\n",
    "                                    date=document_info[0]['date']\n",
    "                                except Exception:\n",
    "                                    date=''\n",
    "                                    print(\"Exception 2, date does not exist\", files)\n",
    "                                                                \n",
    "                                title_en=soup.find('invention-title', attrs={'lang':'EN'})\n",
    "                                if title_en != None:\n",
    "                                    title_en_text=title_en.getText(separator='\\n ')\n",
    "                                   \n",
    "                                abstract_en=soup.find('abstract', attrs={'lang':'EN'})\n",
    "                                if abstract_en != None:\n",
    "                                    abstract_en_text=abstract_en.getText(separator='\\n ')\n",
    "                                                \n",
    "                                description_en = soup.find('description', attrs={'lang':'EN'})\n",
    "                                if description_en != None:\n",
    "                                    description_en_text=description_en.getText('\\n ')\n",
    "                                    \n",
    "                                claims_en = soup.find('claims', attrs={'lang':'EN'})\n",
    "                                if claims_en != None:\n",
    "                                    claims_en_text=claims_en.getText(separator='\\n ')\n",
    "                                        \n",
    "                                df_sum_test.loc[counter_sum-1, 'xml_file_name']=files\n",
    "                                df_sum_test.loc[counter_sum-1, 'ucid']=ucid\n",
    "                                df_sum_test.loc[counter_sum-1, 'date']=date\n",
    "                                df_sum_test.loc[counter_sum-1, 'title_lang_en']=title_en_text\n",
    "                                df_sum_test.loc[counter_sum-1, 'abstract_lang_en']=abstract_en_text\n",
    "                                df_sum_test.loc[counter_sum-1, 'description_lang_en']=description_en_text\n",
    "                                df_sum_test.loc[counter_sum-1, 'claims_lang_en']=claims_en_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06745655",
   "metadata": {},
   "source": [
    "### Identify the patent number and kind code, and append these fields to the initial DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49ca4837",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum_test['patent_number']=df_sum_test['xml_file_name'].str.split(\".\").str[0]\n",
    "df_sum_test['patent_number']=df_sum_test['patent_number'].str.split(\"-\").str[1:2]\n",
    "df_sum_test['patent_number']=df_sum_test['patent_number'].str.join('')\n",
    "\n",
    "df_sum_test['kind_code']=df_sum_test['xml_file_name'].str.split(\".\").str[0]\n",
    "df_sum_test['kind_code']=df_sum_test['kind_code'].str.split(\"-\").str[2:3]\n",
    "df_sum_test['kind_code']=df_sum_test['kind_code'].str.join('')\n",
    "\n",
    "df_sum_test['kind_code_letter']=df_sum_test['kind_code'].str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f31f4d8",
   "metadata": {},
   "source": [
    "### When multiple kind codes exist for a single patent, we merge the most updated information for the selected fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7f71366",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sum_test= df_sum_test.replace('', pd.NA)\n",
    "df_sum_test=df_sum_test.groupby('patent_number').agg({'patent_number':'last', 'kind_code':'last', 'title_lang_en':'last', \\\n",
    "                            'abstract_lang_en':'last', 'description_lang_en':'last', 'claims_lang_en': 'last'})\n",
    "df_sum_test = df_sum_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906a9140",
   "metadata": {},
   "source": [
    "# Brief Description, Summary, and First Claim Extraction (Part III)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2307a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_only_letters_numbers(text):\n",
    "    return re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "\n",
    "#Load the HUPD headings file\n",
    "summary_headings_file='F:/data/exports/summary_headings.csv'\n",
    "summary_headings = pd.read_csv(summary_headings_file, header=0)\n",
    "summary_headings=summary_headings['summary_headings'].tolist()\n",
    "\n",
    "import re\n",
    "\n",
    "# Initialize lists for storing extracted parts\n",
    "brief_list, summary_list, claim_list = [], [], []\n",
    "\n",
    "# Iterate through each row in the DataFrame\n",
    "for i, description in enumerate(df_sum_test['description_lang_en']):\n",
    "    summary_heading_flag = 0\n",
    "    brief_help, summary_help = [], []\n",
    "\n",
    "    # Split description into lines and process each line\n",
    "    for line in description.split(\"\\n\"):\n",
    "        brief_help.append(line)\n",
    "\n",
    "        stripped_line = \" \".join(line.split()).lower()\n",
    "        stripped_line = keep_only_letters_numbers(stripped_line)\n",
    "        #summary flag equal to 0 and still checking for the summary section\n",
    "        if summary_heading_flag == 0:\n",
    "               if stripped_line in summary_headings:\n",
    "                    summary_heading_flag = 1 \n",
    "                    summary_help.append(\" \".join(line.split()))\n",
    "        \n",
    "        #summary flag equal to 1, so we have found the summary section and search to find where it closes\n",
    "        else:\n",
    "            match = re.search(r\"[A-Z][^a-z]* \", line)\n",
    "            if match and \"description\" in match.group(0).strip().lower():\n",
    "                summary_heading_flag = 0\n",
    "                break\n",
    "            else:\n",
    "                summary_help.append(\" \".join(line.split()))\n",
    "            \n",
    "\n",
    "    # Store results for this row\n",
    "    brief_list.append(\" \".join(brief_help))\n",
    "    summary_list.append(\" \".join(summary_help))\n",
    "\n",
    "    # Extract first claim from claims column\n",
    "    claim = df_sum_test['claims_lang_en'][i].split(' 2.')[0] if ' 2.' in df_sum_test['claims_lang_en'][i] else ''\n",
    "    claim_list.append(claim)\n",
    "\n",
    "# Add extracted data to DataFrame\n",
    "df_sum_test['brief_description'] = brief_list\n",
    "df_sum_test['summary'] = summary_list\n",
    "df_sum_test['1st_claim'] = claim_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d51f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of 2847 single patents, we extracted 2847 brief description segments, 1819 summary segments and 132 first claims\n"
     ]
    }
   ],
   "source": [
    "print(\"Out of\", df_sum_test.shape[0], \"single patents, we extracted\", df_sum_test[df_sum_test['brief_description']!=\"\"].shape[0],\\\n",
    "      \"brief description segments,\", df_sum_test[df_sum_test['summary']!=\"\"].shape[0], \"summary segments and\", \\\n",
    "      df_sum_test[df_sum_test['1st_claim']!=\"\"].shape[0], \"first claims\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a42e7bb-4c89-4dd6-b1e4-94ebb19e7504",
   "metadata": {},
   "source": [
    "### Store single patents belonging to the test set 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77e0b9fe-ec34-4589-b673-6eb842e23f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single patents\n",
    "SMTSname=\"SMTSep_VP_\" \n",
    "suffix=\".csv\"\n",
    "df_sum_test.to_csv(destination_path+SMTSname+filename1+suffix, sep =';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be43bcc",
   "metadata": {},
   "source": [
    "#  Additional Criteria for Test Set (Part IV) (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3f9898",
   "metadata": {},
   "source": [
    "## Filtering patents without a distinct summary segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3033c6c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1819, 9)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df_sum_test[df_sum_test['summary']!=\"\"]\n",
    "df=df.reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42241eb1-e029-4949-80ef-a2aa4509a881",
   "metadata": {},
   "source": [
    "### Store single patents belonging to the test set 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f784be7b-f10d-472b-b88b-ce7a8b8a5ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single patents\n",
    "SMTSname=\"SMTSep_VP_\" \n",
    "suffix=\".csv\"\n",
    "df.to_csv(destination_path+SMTSname+filename2+suffix, sep =';')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef55eab4",
   "metadata": {},
   "source": [
    "## Removing patents where the abstract has low similarity with the description and the summary segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1335a931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1819, 10)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df.copy()\n",
    "df1['number_of_words']=None\n",
    "\n",
    "for i in range(0, df1.shape[0]):\n",
    "    summary_valid=df1['summary'][i]\n",
    "    df1.loc[i, 'number_of_words']=len(summary_valid.split())\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c536e1e-8671-4318-9caa-fe04887732ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bert-extractive-summarizer\n",
    "#!pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19776c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\.conda\\envs\\transformer_3_10_v2\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\User\\.conda\\envs\\transformer_3_10_v2\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "import torch\n",
    "from summarizer import Summarizer\n",
    "from summarizer.sbert import SBertSummarizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('anferico/bert-for-patents')\n",
    "model = BertModel.from_pretrained('anferico/bert-for-patents')\n",
    "\n",
    "model2 = SBertSummarizer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cc470b28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patent_number</th>\n",
       "      <th>kind_code</th>\n",
       "      <th>title_lang_en</th>\n",
       "      <th>abstract_lang_en</th>\n",
       "      <th>description_lang_en</th>\n",
       "      <th>claims_lang_en</th>\n",
       "      <th>brief_description</th>\n",
       "      <th>summary</th>\n",
       "      <th>1st_claim</th>\n",
       "      <th>number_of_words</th>\n",
       "      <th>processed_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788455</td>\n",
       "      <td>B1</td>\n",
       "      <td>Method and system for improved control of xero...</td>\n",
       "      <td>A system changes the setpoint of a digital rep...</td>\n",
       "      <td>BACKGROUND AND SUMMARY\\n Digital reprographic ...</td>\n",
       "      <td>A system to control image quality for a laser ...</td>\n",
       "      <td>BACKGROUND AND SUMMARY  Digital reprographic s...</td>\n",
       "      <td>BACKGROUND AND SUMMARY Digital reprographic sy...</td>\n",
       "      <td></td>\n",
       "      <td>653</td>\n",
       "      <td>BACKGROUND AND SUMMARY Digital reprographic sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1798380</td>\n",
       "      <td>B1</td>\n",
       "      <td>Turbine nozzle with spline seal</td>\n",
       "      <td>A method for assembling a gas turbine engine (...</td>\n",
       "      <td>BACKGROUND OF THE INVENTION\\n This invention r...</td>\n",
       "      <td>A turbine nozzle assembly (202) for a gas turb...</td>\n",
       "      <td>BACKGROUND OF THE INVENTION  This invention re...</td>\n",
       "      <td>BRIEF SUMMARY OF THE INVENTION In a further as...</td>\n",
       "      <td></td>\n",
       "      <td>26</td>\n",
       "      <td>BACKGROUND OF THE INVENTION\\n This invention r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1847773</td>\n",
       "      <td>B1</td>\n",
       "      <td>INTEGRATED FLUIDIZED BED ASH COOLER</td>\n",
       "      <td>An integrated fluidized bed ash cooler for a f...</td>\n",
       "      <td>FIELD OF THE INVENTION\\n The present invention...</td>\n",
       "      <td>A fluidized bed ash cooler (100) for cooling b...</td>\n",
       "      <td>FIELD OF THE INVENTION  The present invention ...</td>\n",
       "      <td>SUMMARY OF THE INVENTION Aspects of the invent...</td>\n",
       "      <td></td>\n",
       "      <td>460</td>\n",
       "      <td>FIELD OF THE INVENTION The present invention r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1898530</td>\n",
       "      <td>B1</td>\n",
       "      <td>Communication system, communication apparatus,...</td>\n",
       "      <td>A communication system includes the following ...</td>\n",
       "      <td>CROSS REFERENCES TO RELATED APPLICATIONS\\n The...</td>\n",
       "      <td>An electric-field-coupling antenna used in com...</td>\n",
       "      <td>CROSS REFERENCES TO RELATED APPLICATIONS  The ...</td>\n",
       "      <td>SUMMARY OF THE INVENTION It is desirable to pr...</td>\n",
       "      <td></td>\n",
       "      <td>2146</td>\n",
       "      <td>CROSS REFERENCES TO RELATED APPLICATIONS The p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1918964</td>\n",
       "      <td>B1</td>\n",
       "      <td>Method for measuring information transfer limi...</td>\n",
       "      <td>A crystal thin film is adopted as a specimen f...</td>\n",
       "      <td>BACKGROUND OF THE INVENTION\\n (1) Field of the...</td>\n",
       "      <td>A method for measuring an information transfer...</td>\n",
       "      <td>BACKGROUND OF THE INVENTION  (1) Field of the ...</td>\n",
       "      <td>SUMMARY OF THE INVENTION Accordingly, an objec...</td>\n",
       "      <td></td>\n",
       "      <td>2619</td>\n",
       "      <td>BACKGROUND OF THE INVENTION (1) Field of the I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>2888825</td>\n",
       "      <td>B1</td>\n",
       "      <td>BEAMFORMING</td>\n",
       "      <td>The embodiments herein relate to a method in a...</td>\n",
       "      <td>TECHNICAL FIELD\\n Embodiments herein relate ge...</td>\n",
       "      <td>A method in a transmitter (201) for transmitti...</td>\n",
       "      <td>TECHNICAL FIELD  Embodiments herein relate gen...</td>\n",
       "      <td>SUMMARY An objective of embodiments herein is ...</td>\n",
       "      <td></td>\n",
       "      <td>786</td>\n",
       "      <td>TECHNICAL FIELD Embodiments herein relate gene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1815</th>\n",
       "      <td>2890616</td>\n",
       "      <td>B1</td>\n",
       "      <td>A CARTON FOR PACKING AND A METHOD FOR PACKING ...</td>\n",
       "      <td>The invention relates to a carton for packing ...</td>\n",
       "      <td>FIELD OF INVENTION\\n The present invention rel...</td>\n",
       "      <td>A carton (1) for packing that, when is in a fl...</td>\n",
       "      <td>FIELD OF INVENTION  The present invention rela...</td>\n",
       "      <td>SUMMARY OF THE INVENTION The aim of the presen...</td>\n",
       "      <td></td>\n",
       "      <td>463</td>\n",
       "      <td>FIELD OF INVENTION The present invention relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1816</th>\n",
       "      <td>2897464</td>\n",
       "      <td>B1</td>\n",
       "      <td>EDIBLE WATER-IN-OIL EMULSION AND A PROCESS FOR...</td>\n",
       "      <td>The invention relates to an edible water-in-oi...</td>\n",
       "      <td>Field of invention\\n The present invention rel...</td>\n",
       "      <td>A process for the manufacture of an edible wat...</td>\n",
       "      <td>Field of invention  The present invention rela...</td>\n",
       "      <td>Summary of the invention The inventors have fo...</td>\n",
       "      <td>A process for the manufacture of an edible wat...</td>\n",
       "      <td>7857</td>\n",
       "      <td>Field of invention The present invention relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1817</th>\n",
       "      <td>2904757</td>\n",
       "      <td>B1</td>\n",
       "      <td>THROTTLING A MEDIA STREAM FOR TRANSMISSION VIA...</td>\n",
       "      <td>A method of throttling a media stream, compris...</td>\n",
       "      <td>Technical field\\n The invention relates to a m...</td>\n",
       "      <td>A method (700) of throttling a media stream (3...</td>\n",
       "      <td>Technical field  The invention relates to a me...</td>\n",
       "      <td>Summary It is an object of the invention to pr...</td>\n",
       "      <td></td>\n",
       "      <td>7821</td>\n",
       "      <td>Technical field The invention relates to a met...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>2905223</td>\n",
       "      <td>B1</td>\n",
       "      <td>Variable hub-to-hub phasing rotor system</td>\n",
       "      <td>An aircraft (201) includes a first rotor assem...</td>\n",
       "      <td>BACKGROUND\\n 1. Field of the Invention\\n The p...</td>\n",
       "      <td>An aircraft (201), comprising:\\n\\n a first rot...</td>\n",
       "      <td>BACKGROUND  1. Field of the Invention  The pre...</td>\n",
       "      <td>SUMMARY Aspects and embodiments of the inventi...</td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "      <td>BACKGROUND\\n 1. Field of the Invention\\n The p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1819 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     patent_number kind_code  \\\n",
       "0          1788455        B1   \n",
       "1          1798380        B1   \n",
       "2          1847773        B1   \n",
       "3          1898530        B1   \n",
       "4          1918964        B1   \n",
       "...            ...       ...   \n",
       "1814       2888825        B1   \n",
       "1815       2890616        B1   \n",
       "1816       2897464        B1   \n",
       "1817       2904757        B1   \n",
       "1818       2905223        B1   \n",
       "\n",
       "                                          title_lang_en  \\\n",
       "0     Method and system for improved control of xero...   \n",
       "1                       Turbine nozzle with spline seal   \n",
       "2                   INTEGRATED FLUIDIZED BED ASH COOLER   \n",
       "3     Communication system, communication apparatus,...   \n",
       "4     Method for measuring information transfer limi...   \n",
       "...                                                 ...   \n",
       "1814                                        BEAMFORMING   \n",
       "1815  A CARTON FOR PACKING AND A METHOD FOR PACKING ...   \n",
       "1816  EDIBLE WATER-IN-OIL EMULSION AND A PROCESS FOR...   \n",
       "1817  THROTTLING A MEDIA STREAM FOR TRANSMISSION VIA...   \n",
       "1818           Variable hub-to-hub phasing rotor system   \n",
       "\n",
       "                                       abstract_lang_en  \\\n",
       "0     A system changes the setpoint of a digital rep...   \n",
       "1     A method for assembling a gas turbine engine (...   \n",
       "2     An integrated fluidized bed ash cooler for a f...   \n",
       "3     A communication system includes the following ...   \n",
       "4     A crystal thin film is adopted as a specimen f...   \n",
       "...                                                 ...   \n",
       "1814  The embodiments herein relate to a method in a...   \n",
       "1815  The invention relates to a carton for packing ...   \n",
       "1816  The invention relates to an edible water-in-oi...   \n",
       "1817  A method of throttling a media stream, compris...   \n",
       "1818  An aircraft (201) includes a first rotor assem...   \n",
       "\n",
       "                                    description_lang_en  \\\n",
       "0     BACKGROUND AND SUMMARY\\n Digital reprographic ...   \n",
       "1     BACKGROUND OF THE INVENTION\\n This invention r...   \n",
       "2     FIELD OF THE INVENTION\\n The present invention...   \n",
       "3     CROSS REFERENCES TO RELATED APPLICATIONS\\n The...   \n",
       "4     BACKGROUND OF THE INVENTION\\n (1) Field of the...   \n",
       "...                                                 ...   \n",
       "1814  TECHNICAL FIELD\\n Embodiments herein relate ge...   \n",
       "1815  FIELD OF INVENTION\\n The present invention rel...   \n",
       "1816  Field of invention\\n The present invention rel...   \n",
       "1817  Technical field\\n The invention relates to a m...   \n",
       "1818  BACKGROUND\\n 1. Field of the Invention\\n The p...   \n",
       "\n",
       "                                         claims_lang_en  \\\n",
       "0     A system to control image quality for a laser ...   \n",
       "1     A turbine nozzle assembly (202) for a gas turb...   \n",
       "2     A fluidized bed ash cooler (100) for cooling b...   \n",
       "3     An electric-field-coupling antenna used in com...   \n",
       "4     A method for measuring an information transfer...   \n",
       "...                                                 ...   \n",
       "1814  A method in a transmitter (201) for transmitti...   \n",
       "1815  A carton (1) for packing that, when is in a fl...   \n",
       "1816  A process for the manufacture of an edible wat...   \n",
       "1817  A method (700) of throttling a media stream (3...   \n",
       "1818  An aircraft (201), comprising:\\n\\n a first rot...   \n",
       "\n",
       "                                      brief_description  \\\n",
       "0     BACKGROUND AND SUMMARY  Digital reprographic s...   \n",
       "1     BACKGROUND OF THE INVENTION  This invention re...   \n",
       "2     FIELD OF THE INVENTION  The present invention ...   \n",
       "3     CROSS REFERENCES TO RELATED APPLICATIONS  The ...   \n",
       "4     BACKGROUND OF THE INVENTION  (1) Field of the ...   \n",
       "...                                                 ...   \n",
       "1814  TECHNICAL FIELD  Embodiments herein relate gen...   \n",
       "1815  FIELD OF INVENTION  The present invention rela...   \n",
       "1816  Field of invention  The present invention rela...   \n",
       "1817  Technical field  The invention relates to a me...   \n",
       "1818  BACKGROUND  1. Field of the Invention  The pre...   \n",
       "\n",
       "                                                summary  \\\n",
       "0     BACKGROUND AND SUMMARY Digital reprographic sy...   \n",
       "1     BRIEF SUMMARY OF THE INVENTION In a further as...   \n",
       "2     SUMMARY OF THE INVENTION Aspects of the invent...   \n",
       "3     SUMMARY OF THE INVENTION It is desirable to pr...   \n",
       "4     SUMMARY OF THE INVENTION Accordingly, an objec...   \n",
       "...                                                 ...   \n",
       "1814  SUMMARY An objective of embodiments herein is ...   \n",
       "1815  SUMMARY OF THE INVENTION The aim of the presen...   \n",
       "1816  Summary of the invention The inventors have fo...   \n",
       "1817  Summary It is an object of the invention to pr...   \n",
       "1818  SUMMARY Aspects and embodiments of the inventi...   \n",
       "\n",
       "                                              1st_claim number_of_words  \\\n",
       "0                                                                   653   \n",
       "1                                                                    26   \n",
       "2                                                                   460   \n",
       "3                                                                  2146   \n",
       "4                                                                  2619   \n",
       "...                                                 ...             ...   \n",
       "1814                                                                786   \n",
       "1815                                                                463   \n",
       "1816  A process for the manufacture of an edible wat...            7857   \n",
       "1817                                                               7821   \n",
       "1818                                                                 15   \n",
       "\n",
       "                                  processed_description  \n",
       "0     BACKGROUND AND SUMMARY Digital reprographic sy...  \n",
       "1     BACKGROUND OF THE INVENTION\\n This invention r...  \n",
       "2     FIELD OF THE INVENTION The present invention r...  \n",
       "3     CROSS REFERENCES TO RELATED APPLICATIONS The p...  \n",
       "4     BACKGROUND OF THE INVENTION (1) Field of the I...  \n",
       "...                                                 ...  \n",
       "1814  TECHNICAL FIELD Embodiments herein relate gene...  \n",
       "1815  FIELD OF INVENTION The present invention relat...  \n",
       "1816  Field of invention The present invention relat...  \n",
       "1817  Technical field The invention relates to a met...  \n",
       "1818  BACKGROUND\\n 1. Field of the Invention\\n The p...  \n",
       "\n",
       "[1819 rows x 11 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=0\n",
    "for i in range(df1.shape[0]):\n",
    "    if df1[\"number_of_words\"][i]>350:\n",
    "        #extract_summary=model2(df1['description_lang_en'][i])\n",
    "        extract_summary=df1['description_lang_en'][i].split()[:350]\n",
    "        extract_summary=\" \".join(extract_summary)\n",
    "    else:\n",
    "        extract_summary=df1['description_lang_en'][i]\n",
    "        \n",
    "    df1.loc[i, 'processed_description']=extract_summary\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e1c60d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df1['abstract_lang_en']=df1['abstract_lang_en'].fillna(\"\")\n",
    "\n",
    "similarity_list1 = []\n",
    "similarity_list2 = []\n",
    "\n",
    "for k in range(df1.shape[0]):\n",
    "    print(k)\n",
    "    summary=df1['summary'][k].split()\n",
    "    summary=\" \".join(summary)\n",
    "\n",
    "    abstract=df1['abstract_lang_en'][k].split()\n",
    "    abstract=\" \".join(abstract)\n",
    "\n",
    "    descr=df1['processed_description'][k]\n",
    "    \n",
    "    tokens1 = tokenizer.tokenize(summary)\n",
    "    tokens1 = ['[CLS]'] + tokens1[0:500] + ['[SEP]']\n",
    "    tokens2 = tokenizer.tokenize(abstract)\n",
    "    tokens2 = ['[CLS]'] + tokens2[0:500] + ['[SEP]']\n",
    "    tokens3 = tokenizer.tokenize(descr)\n",
    "    tokens3 = ['[CLS]'] + tokens3[0:500] + ['[SEP]']\n",
    "\n",
    "    # Convert tokens to input IDs\n",
    "    input_ids1 = torch.tensor(tokenizer.convert_tokens_to_ids(tokens1)).unsqueeze(0)  # Batch size 1\n",
    "    input_ids2 = torch.tensor(tokenizer.convert_tokens_to_ids(tokens2)).unsqueeze(0)  # Batch size 1\n",
    "    input_ids3 = torch.tensor(tokenizer.convert_tokens_to_ids(tokens3)).unsqueeze(0)  # Batch size 1\n",
    "\n",
    "    # Obtain the BERT embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs1 = model(input_ids1)\n",
    "        outputs2 = model(input_ids2)\n",
    "        outputs3 = model(input_ids3)\n",
    "\n",
    "        embeddings1 = outputs1.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "        embeddings2 = outputs2.last_hidden_state[:, 0, :]  # [CLS] token           \n",
    "        embeddings3 = outputs3.last_hidden_state[:, 0, :]  # [CLS] token\n",
    "\n",
    "    # Calculate similarity\n",
    "    similarity_score1 = cosine_similarity(embeddings2, embeddings1)\n",
    "    similarity_score2 = cosine_similarity(embeddings2, embeddings3)\n",
    "\n",
    "    #print(similarity_score,k, df.shape[0])\n",
    "    similarity_list1.append(similarity_score1[0][0])\n",
    "    similarity_list2.append(similarity_score2[0][0])\n",
    "\n",
    "df1['similarity_abs_sum']=similarity_list1\n",
    "df1['similarity_abs_descr']=similarity_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50a0308-1c56-4451-8531-f85174b4576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df1[(df1['similarity_abs_sum']>0.70)&(df1['similarity_abs_descr']>0.70)]\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c34c418-3e49-49ee-9664-158843854092",
   "metadata": {},
   "source": [
    "### Store single patents belonging to the test set 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54df48ed-570b-41da-b055-7d7b6d26877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single patents\n",
    "SMTSname=\"SMTSep_VP_\" \n",
    "suffix=\".csv\"\n",
    "df.to_csv(destination_path+SMTSname+filename3+suffix, sep =';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b539329f-84b2-40b1-a0d8-0343064d241a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "1zGbAMn-XSm6d8IebnDcsFzs0Tzayw7Ea",
     "timestamp": 1738226091508
    },
    {
     "file_id": "1osBOU0-CVQo6a77vQTFPjv_O7gDdgh_-",
     "timestamp": 1737980282687
    },
    {
     "file_id": "1mr4EiAzpelueg6H1MNvENO3257L_4qlb",
     "timestamp": 1737933478756
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
